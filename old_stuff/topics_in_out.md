For each, do we primarily use "by hand" calculations or computational calculations / visualization or both with equal weight?

Markov’s and Chebyshev’s inequalities

Sufficient Statistics

Maximum Likelihood Estimation

Method of Moments Estimation

Bias/Variance/MSE of Estimators

Consistency

UMVUE

Cramer-Rao Lower Bound

Finite Sampling Theory (e.g., finite-population correction factor).

Confidence Intervals using Pivots

Confidence Intervals using Bootstrapping

"Conceptual" Confidence Intervals

Simulation of Sampling Distributions

Distributional Proofs (e.g., Proof that if Z ~ N(0,1), then Z^2 ~ Chisq(1), or, proof that (under assumptions) Xbar - mu / (s \ sqrt(n)) follows a T distribution with (n - 1) degrees of freedom).

Bayesian

Neyman-Pearson Hypothesis Testing

Asymptotic LRT

Hypothesis Testing Rejection Regions

Hypothesis tests about variance(s)

Limit Theorems (besides the CLT).

Theory of Regression (e.g., proof that standard regression estimators are the best linear unbiased estimators).

Order statistics

Sample Size Calculations

Power theoretical and Type I/II Errors

Power empirical

Theory of ANOVA

